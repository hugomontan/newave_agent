"""
M√≥dulo para matching sem√¢ntico de tools usando embeddings.
"""
from typing import Optional, Tuple, Dict
import numpy as np
import re
import hashlib
from app.tools.base import NEWAVETool
from app.rag.vectorstore import get_embeddings
from app.config import QUERY_EXPANSION_ENABLED, SEMANTIC_MATCH_MIN_SCORE, safe_print

# Cache global de embeddings das tools
# Estrutura: {tool_name: {'description_hash': str, 'embedding': list[float]}}
_tool_embeddings_cache: Dict[str, Dict] = {}


def clear_tool_embeddings_cache():
    """
    Limpa o cache de embeddings das tools.
    √ötil se as descri√ß√µes das tools forem modificadas.
    """
    global _tool_embeddings_cache
    _tool_embeddings_cache.clear()
    safe_print("[SEMANTIC MATCHER] üóëÔ∏è Cache de embeddings das tools limpo")


def get_cache_stats() -> Dict[str, int]:
    """
    Retorna estat√≠sticas do cache de embeddings.
    
    Returns:
        Dict com estat√≠sticas do cache
    """
    return {
        'cached_tools': len(_tool_embeddings_cache),
        'total_embeddings': len(_tool_embeddings_cache)
    }


def preload_tool_embeddings(tools: list[NEWAVETool]) -> None:
    """
    Pr√©-carrega os embeddings de todas as tools no cache.
    √ötil para melhorar performance na primeira query.
    
    Args:
        tools: Lista de tools para pr√©-carregar embeddings
    """
    if not tools:
        return
    
    safe_print(f"[SEMANTIC MATCHER] üîÑ Pr√©-carregando embeddings de {len(tools)} tools...")
    embeddings_model = get_embeddings()
    
    for tool in tools:
        try:
            _get_tool_embedding(tool, embeddings_model)
        except Exception as e:
            safe_print(f"[SEMANTIC MATCHER] ‚ö†Ô∏è Erro ao pr√©-carregar embedding de {tool.get_name()}: {e}")
    
    cache_stats = get_cache_stats()
    safe_print(f"[SEMANTIC MATCHER] ‚úÖ Pr√©-carregamento conclu√≠do: {cache_stats['cached_tools']} embeddings cacheados")


def expand_query(query: str) -> str:
    """
    Expande a query com sin√¥nimos e varia√ß√µes para melhorar o matching sem√¢ntico.
    
    Args:
        query: Query original do usu√°rio
        
    Returns:
        Query expandida com sin√¥nimos e varia√ß√µes
    """
    if not QUERY_EXPANSION_ENABLED:
        return query
    
    query_lower = query.lower()
    expanded_parts = [query]  # Sempre incluir query original
    
    # Dicion√°rio de expans√µes: termo -> lista de sin√¥nimos/varia√ß√µes
    expansions = {
        # Varia√ß√µes de comandos
        r'\bme d√™\b': ['me de', 'mostre', 'quero ver', 'preciso de', 'quero', 'desejo'],
        r'\bme de\b': ['me d√™', 'mostre', 'quero ver', 'preciso de', 'quero'],
        r'\bmostre\b': ['me d√™', 'me de', 'quero ver', 'preciso de'],
        r'\bquais s√£o\b': ['quais', 'mostre', 'me d√™', 'me de'],
        r'\bqual\b': ['quais', 'mostre', 'me d√™'],
        
        # Carga/Demanda
        r'\bcargas mensais\b': ['demandas mensais', 'consumo mensal', 'carga mensal', 'demanda mensal'],
        r'\bcarga mensal\b': ['demanda mensal', 'consumo mensal', 'cargas mensais', 'demandas mensais'],
        r'\bdemanda mensal\b': ['carga mensal', 'consumo mensal', 'demandas mensais', 'cargas mensais'],
        r'\bdemandas mensais\b': ['cargas mensais', 'consumo mensal', 'demanda mensal', 'carga mensal'],
        r'\bconsumo mensal\b': ['carga mensal', 'demanda mensal', 'cargas mensais', 'demandas mensais'],
        r'\bcarga\b': ['demanda', 'consumo', 'necessidade'],
        r'\bdemanda\b': ['carga', 'consumo', 'necessidade'],
        
        # Submercado/Subsistema
        r'\bpor submercado\b': ['por subsistema', 'por regi√£o', 'do submercado', 'do subsistema'],
        r'\bdo submercado\b': ['do subsistema', 'por submercado', 'por subsistema'],
        r'\bsubmercado\b': ['subsistema', 'regi√£o'],
        r'\bsubsistema\b': ['submercado', 'regi√£o'],
        
        # Modifica√ß√µes h√≠dricas
        r'\bmodifica√ß√µes h√≠dricas\b': ['modifica√ß√£o h√≠drica', 'opera√ß√£o h√≠drica', 'modifica√ß√µes hidrel√©tricas', 'altera√ß√µes hidrel√©tricas'],
        r'\bmodifica√ß√£o h√≠drica\b': ['modifica√ß√µes h√≠dricas', 'opera√ß√£o h√≠drica', 'modifica√ß√µes hidrel√©tricas'],
        r'\bopera√ß√£o h√≠drica\b': ['modifica√ß√µes h√≠dricas', 'modifica√ß√£o h√≠drica', 'operacional h√≠drica'],
        r'\bvolume m√≠nimo\b': ['volumes m√≠nimos', 'volume min', 'vol min'],
        r'\bvolume m√°ximo\b': ['volumes m√°ximos', 'volume max', 'vol max'],
        r'\bvaz√£o m√≠nima\b': ['vaz√µes m√≠nimas', 'vazao minima', 'vaz min'],
        r'\bvaz√£o m√°xima\b': ['vaz√µes m√°ximas', 'vazao maxima', 'vaz max'],
        
        # Opera√ß√£o t√©rmica
        r'\bmodifica√ß√µes t√©rmicas\b': ['modifica√ß√£o t√©rmica', 'opera√ß√£o t√©rmica', 'expans√µes t√©rmicas', 'expans√£o t√©rmica'],
        r'\bexpans√£o t√©rmica\b': ['expans√µes t√©rmicas', 'modifica√ß√µes t√©rmicas', 'opera√ß√£o t√©rmica'],
        r'\bexpans√µes t√©rmicas\b': ['expans√£o t√©rmica', 'modifica√ß√µes t√©rmicas', 'opera√ß√£o t√©rmica'],
        r'\bpot√™ncia efetiva\b': ['potencia efetiva', 'pot efetiva', 'potef'],
        r'\bgera√ß√£o m√≠nima\b': ['geracao minima', 'ger min', 'gtmin'],
        r'\bindisponibilidade programada\b': ['indisponibilidades programadas', 'indisponibilidade', 'ipter'],
        
        # Custos
        r'\bcustos das classes t√©rmicas\b': ['custo da classe t√©rmica', 'custos t√©rmicos', 'valores estruturais', 'valores conjunturais'],
        r'\bclasse t√©rmica\b': ['classes t√©rmicas', 'classe termica', 'classe termel√©trica'],
        r'\bvalores estruturais\b': ['valor estrutural', 'custos base', 'custos estruturais'],
        r'\bvalores conjunturais\b': ['valor conjuntural', 'modifica√ß√µes sazonais', 'ajustes sazonais'],
        r'\bcvu\b': ['custo vari√°vel unit√°rio', 'custo variavel unitario', 'custo unit√°rio vari√°vel'],
    }
    
    # Aplicar expans√µes mantendo contexto
    expanded_queries = [query]  # Sempre incluir query original
    
    for pattern, synonyms in expansions.items():
        if re.search(pattern, query_lower):
            # Para cada sin√¥nimo, criar uma varia√ß√£o da query
            for synonym in synonyms:
                # Substituir o padr√£o pelo sin√¥nimo na query
                expanded = re.sub(pattern, synonym, query_lower, flags=re.IGNORECASE)
                if expanded != query_lower:
                    expanded_queries.append(expanded)
    
    # Adicionar varia√ß√µes comuns
    # Remover pontua√ß√£o
    query_no_punct = re.sub(r'[?!.,;:]', '', query)
    if query_no_punct != query:
        expanded_queries.append(query_no_punct)
    
    # Vers√£o sem acentos (simplificada - apenas casos comuns)
    query_no_accents = query_lower.replace('√£', 'a').replace('√°', 'a').replace('√¢', 'a').replace('√†', 'a')
    query_no_accents = query_no_accents.replace('√©', 'e').replace('√™', 'e')
    query_no_accents = query_no_accents.replace('√≠', 'i').replace('√Æ', 'i')
    query_no_accents = query_no_accents.replace('√≥', 'o').replace('√¥', 'o').replace('√µ', 'o')
    query_no_accents = query_no_accents.replace('√∫', 'u').replace('√ª', 'u')
    query_no_accents = query_no_accents.replace('√ß', 'c')
    if query_no_accents != query_lower:
        expanded_queries.append(query_no_accents)
    
    # Remover duplicatas mantendo ordem
    seen = set()
    unique_queries = []
    for exp_query in expanded_queries:
        exp_lower = exp_query.lower().strip()
        if exp_lower and exp_lower not in seen:
            seen.add(exp_lower)
            unique_queries.append(exp_query)
    
    # Combinar todas as expans√µes em uma √∫nica string
    # Isso ajuda o embedding a capturar todos os sin√¥nimos
    expanded_query = ' '.join(unique_queries)
    
    return expanded_query


def _get_tool_embedding(tool: NEWAVETool, embeddings_model) -> list[float]:
    """
    Obt√©m o embedding de uma tool, usando cache se dispon√≠vel.
    
    Args:
        tool: Tool para obter embedding
        embeddings_model: Modelo de embeddings
        
    Returns:
        Embedding da descri√ß√£o da tool
    """
    tool_name = tool.get_name()
    tool_description = tool.get_description()
    
    # Calcular hash da descri√ß√£o para detectar mudan√ßas
    description_hash = hashlib.md5(tool_description.encode('utf-8')).hexdigest()
    
    # Verificar se j√° temos o embedding em cache e se a descri√ß√£o n√£o mudou
    if tool_name in _tool_embeddings_cache:
        cached = _tool_embeddings_cache[tool_name]
        if cached['description_hash'] == description_hash:
            safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ ‚úÖ Embedding em cache (tool: {tool_name})")
            return cached['embedding']
        else:
            safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ ‚ö†Ô∏è Descri√ß√£o mudou, regenerando embedding (tool: {tool_name})")
    
    # Gerar novo embedding
    safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ üîÑ Gerando novo embedding (tool: {tool_name})")
    embedding = embeddings_model.embed_query(tool_description)
    
    # Armazenar no cache
    _tool_embeddings_cache[tool_name] = {
        'description_hash': description_hash,
        'embedding': embedding
    }
    
    return embedding


def _calculate_cosine_similarity(vec1: list[float], vec2: list[float]) -> float:
    """
    Calcula a similaridade de cosseno entre dois vetores.
    
    Args:
        vec1: Primeiro vetor (embedding)
        vec2: Segundo vetor (embedding)
        
    Returns:
        Similaridade de cosseno (0.0 a 1.0)
    """
    vec1_array = np.array(vec1)
    vec2_array = np.array(vec2)
    
    # Calcular produto escalar
    dot_product = np.dot(vec1_array, vec2_array)
    
    # Calcular normas
    norm1 = np.linalg.norm(vec1_array)
    norm2 = np.linalg.norm(vec2_array)
    
    # Evitar divis√£o por zero
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    # Similaridade de cosseno
    similarity = dot_product / (norm1 * norm2)
    
    # Garantir que est√° no range [0, 1]
    return max(0.0, min(1.0, similarity))


def find_best_tool_semantic(
    query: str, 
    tools: list[NEWAVETool], 
    threshold: float = 0.7
) -> Optional[Tuple[NEWAVETool, float]]:
    """
    Encontra a tool mais relevante usando matching sem√¢ntico.
    
    Gera embeddings da query e das descri√ß√µes de cada tool,
    calcula similaridade de cosseno e retorna a tool com maior
    similaridade se acima do threshold.
    
    Args:
        query: Query do usu√°rio
        tools: Lista de tools dispon√≠veis
        threshold: Threshold m√≠nimo de similaridade (0.0 a 1.0)
        
    Returns:
        Tupla (tool, score) se encontrada tool acima do threshold, ou None
    """
    if not tools:
        safe_print("[SEMANTIC MATCHER] ‚ö†Ô∏è Nenhuma tool dispon√≠vel")
        return None
    
    safe_print("[SEMANTIC MATCHER] ===== IN√çCIO: Semantic Matching =====")
    safe_print(f"[SEMANTIC MATCHER] Query original: \"{query}\"")
    
    # Aplicar query expansion se habilitado
    expanded_query = expand_query(query)
    if expanded_query != query:
        safe_print(f"[SEMANTIC MATCHER] üîç Query Expansion aplicada:")
        safe_print(f"[SEMANTIC MATCHER]   Original: \"{query}\"")
        safe_print(f"[SEMANTIC MATCHER]   Expandida: \"{expanded_query}\"")
    else:
        safe_print(f"[SEMANTIC MATCHER] ‚ö†Ô∏è Query Expansion desabilitada ou sem expans√µes aplicadas")
    
    safe_print(f"[SEMANTIC MATCHER] Threshold (ranking): {threshold:.3f}")
    safe_print(f"[SEMANTIC MATCHER] Score m√≠nimo para executar: {SEMANTIC_MATCH_MIN_SCORE:.3f}")
    safe_print(f"[SEMANTIC MATCHER] Tools dispon√≠veis: {len(tools)}")
    
    # Mostrar estat√≠sticas do cache
    cache_stats = get_cache_stats()
    safe_print(f"[SEMANTIC MATCHER] üì¶ Cache: {cache_stats['cached_tools']} tools com embeddings cacheados")
    
    try:
        # Obter modelo de embeddings
        safe_print("[SEMANTIC MATCHER] Gerando embedding da query...")
        embeddings_model = get_embeddings()
        
        # Gerar embedding da query expandida (ou original se expansion desabilitada)
        query_embedding = embeddings_model.embed_query(expanded_query)
        safe_print(f"[SEMANTIC MATCHER] ‚úÖ Embedding da query gerado (dimens√£o: {len(query_embedding)})")
        
        # Calcular similaridade com cada tool
        best_tool = None
        best_score = 0.0
        all_scores = []  # Para ranking completo
        
        safe_print("[SEMANTIC MATCHER] Calculando similaridades com cada tool...")
        safe_print("[SEMANTIC MATCHER] " + "=" * 70)
        
        for idx, tool in enumerate(tools, 1):
            try:
                tool_name = tool.get_name()
                safe_print(f"[SEMANTIC MATCHER] [{idx}/{len(tools)}] Processando: {tool_name}")
                
                # Obter descri√ß√£o da tool
                tool_description = tool.get_description()
                desc_length = len(tool_description)
                safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ Descri√ß√£o: {desc_length} caracteres")
                
                # Obter embedding da descri√ß√£o (usando cache se dispon√≠vel)
                tool_embedding = _get_tool_embedding(tool, embeddings_model)
                
                # Calcular similaridade de cosseno
                similarity = _calculate_cosine_similarity(query_embedding, tool_embedding)
                
                # Armazenar score para ranking
                all_scores.append({
                    'tool': tool_name,
                    'score': similarity,
                    'above_threshold': similarity >= threshold
                })
                
                # Atualizar melhor match se necess√°rio
                status = "‚úÖ MELHOR" if similarity > best_score else "  "
                threshold_status = "‚úÖ ACIMA" if similarity >= threshold else "‚ùå ABAIXO"
                safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ Similaridade: {similarity:.4f} {status} | Threshold: {threshold_status}")
                
                if similarity > best_score:
                    best_score = similarity
                    best_tool = tool
                    
            except Exception as e:
                # Se houver erro ao processar uma tool, continuar com as outras
                safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ ‚ùå Erro ao processar: {e}")
                all_scores.append({
                    'tool': tool.get_name(),
                    'score': 0.0,
                    'above_threshold': False,
                    'error': str(e)
                })
                continue
        
        safe_print("[SEMANTIC MATCHER] " + "=" * 70)
        
        # Mostrar ranking completo
        safe_print("[SEMANTIC MATCHER] üìä RANKING DE SIMILARIDADE:")
        all_scores_sorted = sorted(all_scores, key=lambda x: x['score'], reverse=True)
        for rank, item in enumerate(all_scores_sorted, 1):
            tool_name = item['tool']
            score = item['score']
            above = "‚úÖ" if item['above_threshold'] else "‚ùå"
            marker = "üèÜ" if rank == 1 else "  "
            safe_print(f"[SEMANTIC MATCHER]   {marker} {rank}. {tool_name}: {score:.4f} {above} (threshold: {threshold:.3f})")
        
        # Nova regra: Se score >= 0.4, sempre executar a tool com maior score
        # Se score < 0.4, nenhuma tool √© executada (fluxo normal assume)
        safe_print("[SEMANTIC MATCHER] " + "=" * 70)
        safe_print(f"[SEMANTIC MATCHER] üìã REGRA DE DECIS√ÉO:")
        safe_print(f"[SEMANTIC MATCHER]   - Score >= {SEMANTIC_MATCH_MIN_SCORE:.3f}: Tool ser√° executada")
        safe_print(f"[SEMANTIC MATCHER]   - Score < {SEMANTIC_MATCH_MIN_SCORE:.3f}: Nenhuma tool (fluxo normal)")
        
        if best_tool and best_score >= SEMANTIC_MATCH_MIN_SCORE:
            safe_print(f"[SEMANTIC MATCHER] ‚úÖ TOOL SELECIONADA PARA EXECU√á√ÉO!")
            safe_print(f"[SEMANTIC MATCHER]   Tool: {best_tool.get_name()}")
            safe_print(f"[SEMANTIC MATCHER]   Score: {best_score:.4f}")
            safe_print(f"[SEMANTIC MATCHER]   Score m√≠nimo: {SEMANTIC_MATCH_MIN_SCORE:.3f}")
            safe_print(f"[SEMANTIC MATCHER]   Status: ‚úÖ ACIMA DO M√çNIMO (tool ser√° executada)")
            safe_print("[SEMANTIC MATCHER] ===== FIM: Semantic Matching (TOOL SELECIONADA) =====")
            return (best_tool, best_score)
        else:
            if best_tool:
                safe_print(f"[SEMANTIC MATCHER] ‚ùå NENHUMA TOOL SER√Å EXECUTADA")
                safe_print(f"[SEMANTIC MATCHER]   Melhor tool: {best_tool.get_name()}")
                safe_print(f"[SEMANTIC MATCHER]   Melhor score: {best_score:.4f}")
                safe_print(f"[SEMANTIC MATCHER]   Score m√≠nimo necess√°rio: {SEMANTIC_MATCH_MIN_SCORE:.3f}")
                safe_print(f"[SEMANTIC MATCHER]   Diferen√ßa: {best_score - SEMANTIC_MATCH_MIN_SCORE:.4f} (faltam {SEMANTIC_MATCH_MIN_SCORE - best_score:.4f})")
                safe_print(f"[SEMANTIC MATCHER]   ‚Üí Fluxo normal (coder/executor) assumir√°")
            else:
                safe_print(f"[SEMANTIC MATCHER] ‚ùå NENHUMA TOOL PROCESSADA COM SUCESSO")
                safe_print(f"[SEMANTIC MATCHER]   ‚Üí Fluxo normal (coder/executor) assumir√°")
            safe_print("[SEMANTIC MATCHER] ===== FIM: Semantic Matching (FLUXO NORMAL) =====")
            return None
            
    except Exception as e:
        safe_print(f"[SEMANTIC MATCHER] ‚ùå Erro no matching sem√¢ntico: {e}")
        import traceback
        traceback.print_exc()
        safe_print("[SEMANTIC MATCHER] ===== FIM: Semantic Matching (ERRO) =====")
        return None


def find_top_tools_semantic(
    query: str,
    tools: list[NEWAVETool],
    top_n: int = 3,
    threshold: float = 0.55
) -> list[Tuple[NEWAVETool, float]]:
    """
    Encontra as top N tools mais relevantes usando matching sem√¢ntico.
    Baseado na an√°lise emp√≠rica, retorna at√© 3 tools candidatas.
    
    Args:
        query: Query do usu√°rio
        tools: Lista de tools dispon√≠veis
        top_n: N√∫mero m√°ximo de tools a retornar (padr√£o: 3)
        threshold: Threshold m√≠nimo de similaridade para ranking
        
    Returns:
        Lista de tuplas (tool, score) ordenadas por score decrescente
    """
    if not tools:
        safe_print("[SEMANTIC MATCHER] ‚ö†Ô∏è Nenhuma tool dispon√≠vel")
        return []
    
    safe_print(f"[SEMANTIC MATCHER] ===== IN√çCIO: find_top_tools_semantic (top_n={top_n}) =====")
    safe_print(f"[SEMANTIC MATCHER] Query: \"{query}\"")
    
    # Aplicar query expansion se habilitado
    expanded_query = expand_query(query)
    
    try:
        # Obter modelo de embeddings
        embeddings_model = get_embeddings()
        
        # Gerar embedding da query expandida
        query_embedding = embeddings_model.embed_query(expanded_query)
        
        # Calcular similaridade com cada tool
        all_scores = []
        
        for tool in tools:
            try:
                tool_name = tool.get_name()
                
                # Obter embedding da descri√ß√£o (usando cache se dispon√≠vel)
                tool_embedding = _get_tool_embedding(tool, embeddings_model)
                
                # Calcular similaridade de cosseno
                similarity = _calculate_cosine_similarity(query_embedding, tool_embedding)
                
                # Armazenar score
                all_scores.append((tool, similarity))
                    
            except Exception as e:
                safe_print(f"[SEMANTIC MATCHER]   ‚îî‚îÄ ‚ùå Erro ao processar {tool.get_name()}: {e}")
                continue
        
        # Ordenar por score decrescente
        all_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Mostrar ranking completo de scores
        safe_print(f"[SEMANTIC MATCHER] üìä RANKING COMPLETO DE SCORES ({len(all_scores)} tools):")
        for idx, (tool, score) in enumerate(all_scores[:10], 1):  # Mostrar top 10
            status = "‚úÖ" if score >= threshold else "‚ùå"
            safe_print(f"[SEMANTIC MATCHER]   {idx}. {tool.get_name()}: {score:.4f} {status} (threshold: {threshold:.3f})")
        if len(all_scores) > 10:
            safe_print(f"[SEMANTIC MATCHER]   ... ({len(all_scores) - 10} tools restantes)")
        
        # Filtrar por threshold e retornar top N
        filtered_scores = [(tool, score) for tool, score in all_scores if score >= threshold]
        top_tools = filtered_scores[:top_n]
        
        safe_print(f"[SEMANTIC MATCHER] ‚úÖ Top {len(top_tools)} tools encontradas (ap√≥s filtro threshold={threshold:.3f}):")
        for idx, (tool, score) in enumerate(top_tools, 1):
            safe_print(f"[SEMANTIC MATCHER]   {idx}. {tool.get_name()}: {score:.4f}")
        
        if len(top_tools) >= 2:
            score_diff = top_tools[0][1] - top_tools[1][1]
            safe_print(f"[SEMANTIC MATCHER]   üìè Diferen√ßa 1¬∫-2¬∫: {score_diff:.4f}")
        
        safe_print("[SEMANTIC MATCHER] ===== FIM: find_top_tools_semantic =====")
        return top_tools
            
    except Exception as e:
        safe_print(f"[SEMANTIC MATCHER] ‚ùå Erro no find_top_tools_semantic: {e}")
        import traceback
        traceback.print_exc()
        return []

